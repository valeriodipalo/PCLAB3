{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 2\n",
    "I will include some of the steps in the task 2 to start from the proper dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def word_count_col(df, text, new_col_name):\n",
    "    \"\"\"This function will define the number of words in each row of the considered dataframe\n",
    "    df: dataframe to use\n",
    "    text: the text column in the dataframe\n",
    "    new_col_name: the name to which associate the column of word count\"\"\"\n",
    "    tot = len(df)\n",
    "    words = []\n",
    "    for i in range(tot):\n",
    "        words.append(len(df[text][i].split()))\n",
    "    df[new_col_name] = words\n",
    "    return df\n",
    "\n",
    "def preprocess(input_text):\n",
    "    \"\"\"This function will allow us to perform all the preprocessing steps to reduce noise in text data. This is fundamental to perform text analysis.\n",
    "    The function will return a list of cleaned sentences\"\"\"\n",
    "\n",
    "    # Normalize to lowercase\n",
    "    txt = input_text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    txt = re.sub('https?://\\S+|www\\.\\S+', '', txt)\n",
    "\n",
    "    # Remove numbers\n",
    "    txt = re.sub(r\"\\d\", \"\", txt)\n",
    "\n",
    "    # Remove punctuation\n",
    "    txt = re.sub('\\n', '', txt)\n",
    "    txt = re.sub(r\"[^A-Za-z]+\", \" \", txt)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = [w.lower() for w in stopwords.words('english')]\n",
    "    stop_words = set(stop_words).difference(set(['against','above','below', 'over', 'under']))\n",
    "    txt = ' '.join([w for w in txt.split() if w not in stop_words and w !='user'])\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmas = [token.lemma_ for token in nlp(txt)]\n",
    "    txt = \" \".join(lemmas)\n",
    "\n",
    "    return txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mI0_cfHE0GB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = word_count_col(data,'Text','pre_word_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyxsJcUKE0GB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "documents = data[\"Text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLhOCo68E0GB",
    "outputId": "5dbef08e-a5f3-47ed-93a8-0830d540caea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "%time clean_des = [preprocess(string) for string in documents[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMjexL0ME0GC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['clean_text'] = clean_des\n",
    "data = word_count_col(data,'clean_text','post_word_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "mFSpgpToE0GC",
    "outputId": "f73d4dc7-b648-41f9-ae68-f777280b92b2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sToYtypiE0GD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz6lcGPgE0GD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, RNN, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w87pWyUwJk5v",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_text = data.clean_text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_gTGffdoE0GE",
    "outputId": "77643493-ef9c-4203-e9ba-602de0af645d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#this cell is not useful for tokenizing and padding, but just to evaluate how many tokens we have before to proceed\n",
    "#takes time to run; the result is 49483\n",
    "\n",
    "#tokens = [[token.text for token in nlp(sentence)] for sentence in clean_text]\n",
    "#count = 0\n",
    "#for l in tokens:\n",
    "#  for w in l:\n",
    "#    count += 1 \n",
    "#print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYt8oLODLnm_",
    "outputId": "bddb820f-0808-489a-ad1a-a5e08167ddad",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TOKENIZING: First trial, get a strange result as i am not able to include more words reducing the num_words which should represent the minimum frequency for a word to be included \n",
    "# tokenizer = Tokenizer(num_words=100000000, lower= 1, oov_token=\"<OOV>\")\n",
    "# tokenizer.fit_on_texts(clean_text)\n",
    "# word_index = tokenizer.word_index\n",
    "# print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0QeQxmOS_wn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TOKENIZING \n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(clean_text)\n",
    "\n",
    "tk.num_words = 1000\n",
    "word_index = tk.word_index\n",
    "#print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMm_FRVQPP9H",
    "outputId": "1cf5f39a-e6cb-4026-cc03-cb6d1efdf9be",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SEQUENCES \n",
    "sequences = tk.texts_to_sequences(clean_text)\n",
    "print(clean_text)\n",
    "print(word_index)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJDatRYGL-w6",
    "outputId": "f57fa2ac-1ac7-4eb8-d668-a6a4fb5ec6bb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PADDING \n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding=\"post\")\n",
    "print(padded_inputs)\n",
    "X = padded_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot2vlViFaIDz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ub0X4l_CValg",
    "outputId": "2fca167c-0e6b-41fb-deb2-3b787d9dbc7b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(Embedding(500, 120, input_length = X.shape[1]))\n",
    "model_LSTM.add(SpatialDropout1D(0.4))\n",
    "model_LSTM.add(LSTM(176, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_LSTM.add(Dense(2,activation='softmax'))\n",
    "model_LSTM.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model_LSTM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UrQAiaSXvb_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = pd.get_dummies(data['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pw7xYHVeX64U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2MphKHiHX8DJ",
    "outputId": "ad7b5885-cdda-419e-c268-09b58a1596ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "# model_LSTM.fit(X_train, y_train, epochs = 10, batch_size=batch_size, verbose = 'auto')\n",
    "model_LSTM.fit(X_train, y_train, epochs = 1, batch_size=batch_size, verbose = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6s7jRLDQ2Rra",
    "outputId": "bed8fc73-2b8b-4949-bbad-1dc688f0b55c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model_LSTM.evaluate(X_test,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R3MJP5dy1B-_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "Ik7D-eJO-M5g",
    "outputId": "33d38985-9918-4e8f-b634-e0194fd5720a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = y_test.iloc[:,1]\n",
    "y_pred = model_LSTM.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZ6YeUhQaSv8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bi-LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6W6G4NSatCH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqG57RpZaRXu",
    "outputId": "302aef25-b11d-44c8-b46f-476f1941f36d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_BI = Sequential()\n",
    "model_BI.add(Embedding(500, 120, input_length = X.shape[1]))\n",
    "model_BI.add(SpatialDropout1D(0.4))\n",
    "model_BI.add(Bidirectional(LSTM(176, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model_BI.add(Dense(2,activation='softmax'))\n",
    "model_BI.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model_BI.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gbQgAvkak3L",
    "outputId": "93de8127-97d8-4a5f-8343-08331e06af50",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "# model_BI.fit(X_train, y_train, epochs = 10, batch_size=batch_size, verbose = 'auto')\n",
    "model_BI.fit(X_train, y_train, epochs = 1, batch_size=batch_size, verbose = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDXMQNdV-YgC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model_BI.evaluate(X_test,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "YvQ6OS5S_L3w",
    "outputId": "7e3c211f-73e7-4b27-a89d-b09a167caeec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model_BI.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFkDT9Sc-YpB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = y_test.iloc[:,1]\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzpqWvCX-gY2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NYwrzZUdDRd",
    "outputId": "7266e18e-9016-46c8-d73b-bc6a6101d51f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_SimpleRNN = Sequential()\n",
    "model_SimpleRNN.add(Embedding(500, 120, input_length = X.shape[1]))\n",
    "model_SimpleRNN.add(SpatialDropout1D(0.4))\n",
    "model_SimpleRNN.add(SimpleRNN(176))\n",
    "model_SimpleRNN.add(Dense(2,activation='softmax'))\n",
    "model_SimpleRNN.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model_SimpleRNN.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZmDZnqPq9LY",
    "outputId": "6cf5dbc6-f3b6-437b-836a-6c829b3be5db",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "model_SimpleRNN.fit(X_train, y_train, epochs = 1, batch_size=batch_size, verbose = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6agJjMp1tP--",
    "outputId": "923c9a57-27cb-4019-8159-c1731011899d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_SimpleRNN.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "fP8TC4OAuz10",
    "outputId": "a9012dc4-df77-40d8-edb4-2da5bd07136f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model_SimpleRNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUJdzr431Wkn",
    "outputId": "47d47bd3-25ad-4c49-cb89-cf6d47ad8085",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred=np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBtbSilUyjst",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model_SimpleRNN.evaluate(X_test,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XutVVLay1jZ3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = y_test.iloc[:,1]\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdU5Dy9N1h7t",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-a-oq7MjymEx",
    "outputId": "f279f840-c6d8-4ce8-c4a1-965cbc4210c5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btJ4TgavzLbe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}